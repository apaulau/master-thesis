prediction.kriging <- data.frame("Temperature"=c(temperature[(OBS_NUM-1):OBS_NUM], trend[(OBS_NUM+1):38]+kriging$var1.pred),
"Year"=c((2012-38+OBS_NUM-1):2012))
actual <- data.frame("Temperature"=temperature[(OBS_NUM-1):38],
"Year"=c((2012-38+OBS_NUM-1):2012))
if (nchar(file_prediction)) {
plot.crossprediction <- ggplot() +
geom_line(data=prediction.kriging, aes(x=Year, y=Temperature, color="Прогноз Кригинг")) +
geom_line(data=prediction.trend, aes(x=Year, y=Temperature, color="Прогноз Тренд")) +
geom_line(data=actual, aes(x=Year, y=Temperature, colour="Актуальное")) +
scale_x_continuous(breaks=seq(min(actual$Year), max(actual$Year)+5, by=1)) + xlab("Год наблюдения") +
scale_y_continuous(breaks=seq(16, 28, .5)) + ylab("Температура, ºС") +
theme(axis.text.x = element_text(angle=45, hjust=1)) +
labs(color="")
ggsave(plot=plot.crossprediction, file=file_prediction, width=7, height=4)
}
prediction.kriging$Temperature[3:(38-OBS_NUM)]-actual$Temperature[3:(38-OBS_NUM)]
}
OBS_NUM <- 32
src <- read.csv(file="data/batorino_july.csv", header=TRUE, sep=";", nrows=38, colClasses=c("numeric", "numeric"), stringsAsFactors=FALSE)
src$Year <- c(1:38)
src.fit <- lm(src$temperature ~ src$year)
src.res <- src.fit$residuals
src.trend <- src.fit$fitted.values
cutoff <- trunc(2 * OBS_NUM / 3) # let it be "classical" value
#cutoff <- 2
variogram.classical <- calcVariogram(data=src.res[1:OBS_NUM], x=src$Year[1:OBS_NUM], cressie=F, cutoff=cutoff, width=F,
file_empirical="figures/variog_classical_emp.png",
file_modeled="figures/variog_classical_mod.png")
variogram.robust <- calcVariogram(data=src.res[1:OBS_NUM], x=src$Year[1:OBS_NUM], cressie=T, cutoff=cutoff, width=F,
file_empirical="figures/variog_robust_emp.png",
file_modeled="figures/variog_robust_mod.png")
kriging.classical <- predictKrige(src.res[1:OBS_NUM], x=src$Year[1:OBS_NUM], variogram_model=variogram.classical$var_model)
kriging.robust <- predictKrige(src.res[1:OBS_NUM], x=src$Year[1:OBS_NUM], variogram_model=variogram.robust$var_model)
res.cl <- crossPrediction(src$temperature, src.trend, kriging.classical, "figures/cross_prediction_classical.png")
res.ro <- crossPrediction(src$temperature, src.trend, kriging.robust, "figures/cross_prediction_robust.png")
## TODO: form krige matrix for analysis
source('~/study/diploma/R/tmp_va.r', echo=TRUE)
checkDependency(data=src[1:OBS_NUM])
checkDependency(data=src[1:OBS_NUM], x=src$Year[1:OBS_NUM])
src$Year[1:OBS_NUM]
qplot
library(ggplot2)  # eye-candy graphs
?ggplot
* Variogram analysis must be converted to eye-candy view
c(1:10)[0]
c(1:10)[1]
c(1:10)[length(c(1:10))]
convertYears(years) {
c(1:years[length(years)] - years[1])
}
convertYears(years) {
convertYears <- function(years) {
c(1:years[length(years)] - years[1])
}
convertYears(src.data$year)
src.data$year
src.data$year[length(src.data$year)]
src.data$year[size(src.data$year)]
src.data$year[size(src.data$year)]
src.data$year[length(src.data$year)]
?length
src.data$year[length(src.data$year)]
src.data$year[1]
convertYears <- function(years) {
c(1:(years[length(years)] - years[1]))
}
convertYears(src.data$year)
help(closures)
help(closure)
?line
cars
line(data.frame(c(1,2,3),c(1,2,3)))
coef(line(data.frame(c(1,2,3),c(1,2,3))))
abline(coef(line(data.frame(c(1,2,3),c(1,2,3)))))
plot()
plot(data.frame(c(1,2,3),c(1,2,3)))
abline(coef(line(data.frame(c(1,2,3),c(1,2,3)))))
source("variogram.R")
source("R/variogram.R")
?local
?attach
test
c(plot)
c
a <- c(plot)
a
a[1]
a[1](1)
a[1](c(1)
)
ntest.shapiro(rnorm(1000), 'test.txt')
worker <- function (test, data, filename, ...) {
result <- func(data, ...)
to.file(data = result, filename = filename)
result
}
# Shapiro-Wilk test for normality
ntest.shapiro <- function (data, filename, ...) {
worker(shapiro.test, data, filename, ...)
}
ntest.shapiro(rnorm(1000), 'test.txt')
worker <- function (test, data, filename, ...) {
result <- test(data, ...)
to.file(data = result, filename = filename)
result
}
# Shapiro-Wilk test for normality
ntest.shapiro <- function (data, filename, ...) {
worker(shapiro.test, data, filename, ...)
}
ntest.shapiro(rnorm(1000), 'test.txt')
worker <- function (test, data, filename, ...) {
result <- test(data, ...)
to.file(result, filename)
result
}
# Shapiro-Wilk test for normality
ntest.shapiro <- function (data, filename, ...) {
worker(shapiro.test, data, filename, ...)
}
ntest.shapiro(rnorm(1000), 'test.txt')
worker <- function (test, data, filename, ...) {
result <- test(data, ...)
if (nchar(filename)) {
to.file(result, filename)
}
result
}
# Shapiro-Wilk test for normality
ntest.shapiro <- function (data, filename, ...) {
worker(shapiro.test, data, filename, ...)
}
ntest.shapiro(rnorm(1000), '')
ntest.shapiro(rnorm(1000), '123')
ntest.shapiro(rnorm(1000))
worker <- function (test, data, filename='', ...) {
result <- test(data, ...)
if (nchar(filename)) {
to.file(result, filename)
}
result
}
# Shapiro-Wilk test for normality
ntest.shapiro <- function (data, filename, ...) {
worker(shapiro.test, data, filename, ...)
}
ntest.shapiro(rnorm(1000))
worker <- function (test, data, filename="", ...) {
result <- test(data, ...)
if (nchar(filename)) {
to.file(result, filename)
}
result
}
# Shapiro-Wilk test for normality
ntest.shapiro <- function (data, filename, ...) {
worker(shapiro.test, data, filename, ...)
}
ntest.shapiro(rnorm(1000))
nchar("")
worker <- function (test, data, filename="", ...) {
result <- test(data, ...)
if (nchar(filename)) {
to.file(result, filename)
}
result
}
# Shapiro-Wilk test for normality
ntest.shapiro <- function (data, filename="", ...) {
worker(shapiro.test, data, filename, ...)
}
ntest.shapiro(rnorm(1000))
library(nortest)  # tests for normality // WANT TO STEAL
ntest.KolmogorovSmirnov <- function (data, filename="", ...) {
nsample <- rnorm(10000, mean=mean(research.data$temperature), sd=sd(research.data$temperature)) # sample for test against source
worker(ks.test, data, filename, y=nsample, exact=NULL, ...)
}
ntest.KolmogorovSmirnov(rnorm(10))
test.nsample <- rnorm(10000, mean=mean(research.data$temperature), sd=sd(research.data$temperature)) # sample for test against source
ks.test(x=rnorm(10), y=test.nsample, exact=NULL)
ks.test(x=rnorm(100), y=test.nsample, exact=NULL)
ks.test(x=runif(10), y=test.nsample, exact=NULL)
ks.test(x=runif(100), y=test.nsample, exact=NULL)
source("R/lib/ntest.R")        # tests for normality
paste("1", "2", "3", sep="/")
paste("1", "", "3", sep="/")
rm(list=ls(all=TRUE))
## Dependencies
library(ggplot2)  # eye-candy graphs
library(xtable)   # convert data to latex tables
library(outliers) # tests for outliers
library(tseries)  # adf test used
library(nortest)  # tests for normality
library(sp)       # spatial data
library(gstat)    # geostatistics
library(reshape2) # will see
library(spatial)
rm(list=ls(all=TRUE))
## Dependencies
library(ggplot2)  # eye-candy graphs
library(xtable)   # convert data to latex tables
library(outliers) # tests for outliers
library(tseries)  # adf test used
library(nortest)  # tests for normality
library(sp)       # spatial data
library(gstat)    # geostatistics
library(reshape2) # will see
## Import local modules
source("R/lib/plot.R")       # useful functions for more comfortable plotting
source("R/lib/print.R")      # functions for print some data to files
source("R/lib/dstats.R")     # descriptive statistics module
source("R/lib/misc.R")       # some useful global-use functions
source("R/lib/draw.R")       # helpers for drawing
source("R/lib/ntest.R")      # tests for normality
source("R/lib/ntest.R")      # tests for normality
source("R/lib/ntest.R")      # tests for normality
source("R/lib/ntest.R")      # tests for normality
library(nortest)  # tests for normality // WANT TO STEAL
worker <- function (test, data, filename, y, ...) {
result <- test(data, ...)
if (nchar(filename)) {
to.file(result, filename)
}
result
}
# Shapiro-Wilk test for normality
ntest.ShapiroWilk <- function (data, filename="", ...) {
worker(shapiro.test, data, filename, ...)
}
ntest.PearsonChi2 <- function (data, filename="", ...) {
worker(pearson.test, data, filename, ...)
}
ntest.KolmogorovSmirnov <- function (data, filename="", ...) {
nsample <- rnorm(10000, mean=mean(data), sd=sd(data) # sample for test against source
worker(ks.test, data, filename, y=nsample, ...)
}
ntest.KolmogorovSmirnov <- function (data, filename="", ...) {
nsample <- rnorm(10000, mean=mean(data), sd=sd(data) # sample for test against source
worker(ks.test, data, filename, ...)
}
ntest.KolmogorovSmirnov <- function (data, filename="", ...) {
nsample <- rnorm(10000, mean=mean(data), sd=sd(data)) # sample for test against source
worker(ks.test, data, filename, y=nsample, ...)
}
source("R/lib/ntest.R")      # tests for normality
## Read the data / pattern: year;temperature
path.data <- "data/batorino_july.csv" # this for future shiny support and may be choosing multiple data sources
src.nrows <- 38
src.data  <- read.csv(file=path.data, header=TRUE, sep=";", nrows=src.nrows, colClasses=c("numeric", "numeric"), stringsAsFactors=FALSE)
## Source data as basic time series plot: points connected with line
plot.source <- DrawDataRepresentation(data=src.data, filename="source.png", datebreaks=kDateBreaks)
kDateBreaks <- seq(min(src.data$year) - 5, max(src.data$year) + 5, by=2) # date points for graphs
## For the reason of prediction estimation and comparison, let cut observations number by 3
kObservationNum <- length(src.data[, 1]) - 3
## Source data as basic time series plot: points connected with line
plot.source <- DrawDataRepresentation(data=src.data, filename="source.png", datebreaks=kDateBreaks)
print(xtable(src.data, caption="Исходные данные.", label="table:source"),  table.placement="H",
file="out/original/data.tex")
## Form the data for research
research.data <- src.data[0:kObservationNum, ]
# Getting descriptive statistics for temperature in russian locale
research.data.dstats <- dstats.describe(research.data$temperature, locale=TRUE)
print(xtable(research.data.dstats, caption="Описательные статистики для наблюдаемых температур.", label="table:dstats"),
file="out/original/dstats.tex")
## Basic histogram based on Sturges rule (by default) with pretty output (also by default)
plot.data.hist <- DrawHistogram(data=research.data, filename="original/histogram.png", datebreaks=kDateBreaks)
## Tests for normality
research.data.shapiro <- ntest.ShapiroWilk(data=research.data$temperature, filename="out/original/shapiro-test.tex")
research.data.pearson <- ntest.PearsonChi2(data=research.data$temperature, filename="out/original/pearson-test.tex")
research.data.ks      <- ntest.KolmogorovSmirnov(data=research.data$temperature, filename="out/original/ks-test.tex")
## Normal Quantile-Quantile plot // TODO: check when it appears in text
plot.data.qq <- DrawQuantileQunatile(data=research.data$temperature, filename="original/quantile.png")
source("R/lib/draw.R")       # helpers for drawing
plot.data.qq <- DrawQuantileQunatile(data=research.data$temperature, filename="original/quantile.png")
source("R/lib/draw.R")       # helpers for drawing
plot.data.qq <- DrawQuantileQunatile(data=research.data$temperature, filename="original/quantile.png")
## Scatter plot with regression line
plot.data.scatter <- DrawScatterPlot(research.data, filename="original/scatterplot.png", kDateBreaks);
## Grubbs test for outliers
research.data.grubbs <- grubbs.test(research.data$temperature)
to.file(research.data.grubbs, "out/original/grubbs-test.tex")
## Correlation matrix
research.data.cmatrix <- cor(cbind("Temperature"=research.data$temperature, "Date"=1:kObservationNum), method="pearson")
print(xtable(research.data.cmatrix, caption="Корреляционная матрица.", label="table:cmatrix"),
file="out/original/corr-matrix.tex")
## Pearson's product-moment correlation test. Use time for y as numerical
research.data.ctest <- cor.test(research.data$temperature, c(1:kObservationNum), method="pearson")
to.file(research.data.ctest, "out/original/corr-test.tex")
## Fitting linear model for researching data. It also compute residuals based on subtracted regression
research.data.fit <- lm(research.data$temperature ~ c(1:kObservationNum))
research.data.fit
## Time series (which is by default is research data) with trend line based on linear module estimate (lm)
plot.data.ts <- DrawTimeSeries(data=research.data, filename="original/time-series.png", datebreaks=kDateBreaks)
DrawTimeSeries  <- function (data, filename, datebreaks) {
plot.ts <- ggplot(data, aes(x=year, y=temperature)) +
geom_point() + geom_line() + stat_smooth(method=lm, se=FALSE) +
scale_x_continuous(breaks=datebreaks) + scale_y_continuous(breaks=seq(16, 28, 1)) +
theme(axis.text.x=element_text(angle=45, hjust=1)) + xlab("Год наблюдения") + ylab("Температура, ºС")
plot.save(plot.ts, filename=filename)
plot.ts
}
plot.data.ts <- DrawTimeSeries(data=research.data, filename="original/time-series.png", datebreaks=kDateBreaks)
research.residuals <- data.frame("year"=research.data$year, "temperature"=research.data.fit$residuals)
print(xtable(research.residuals, caption="Временной ряд остатков.", label="table:residuals"), table.placement="H",
file="out/residual/data.tex")
plot.residuals.ts <- DrawTimeSeries(data=research.residuals, filename="residual/time-series.png", datebreaks=kDateBreaks)
## Descriptive statistics for residuals
research.residuals.dstats <- dstats.describe(research.residuals$temperature, locale=TRUE)
print(xtable(research.residuals.dstats, caption="Описательные статистики для остатков.", label="table:residuals_dstats"),
file="out/residuals_dstats.tex")
## Basic histogram for residuals / seems like the same as for non-residuals
plot.residuals.hist <- DrawHistogram(data=research.residuals, filename="residual/histogram.png", datebreaks=kDateBreaks)
## Tests for normality
research.data.shapiro <- ntest.ShapiroWilk(data=research.residuals$temperature, filename="out/residual/shapiro-test.tex")
research.data.pearson <- ntest.PearsonChi2(data=research.residuals$temperature, filename="out/residual/pearson-test.tex")
research.data.ks      <- ntest.KolmogorovSmirnov(data=research.residuals$temperature, filename="out/residual/ks-test.tex")
## Normal Quantile-Quantile plot for residuals
plot.residuals.qq <- DrawQuantileQunatile(data=research.residuals$temperature, filename="residual/qunatile.png")
## Auto Correlation Function plot // TODO: check the style
plot.residuals.acf <- DrawAutoCorrelationFunction(data=research.data$temperature, filename="residual/acf.png")
DrawAutoCorrelationFunction <- function (data, filename) {
plot.acf <- ggacf(data)
plot.save(plot.acf, filename=filename)
plot.acf
}
plot.residuals.acf <- DrawAutoCorrelationFunction(data=research.data$temperature, filename="residual/acf.png")
plot.residuals.acf
research.residuals.box <- Box.test(research.residuals$temperature, type="Ljung-Box")
to.file(research.residuals.box, "out/residual/ljung-test.tex")
research.residuals.adf <- adf.test(research.residuals$temperature)
to.file(research.residuals.adf, "out/residual/stationarity-test.tex")
# Let's start from beginning.
# This file will be the master file of all diploma project's files (slaves).
# Content will be the same as for previous works (batorino analysis).
# Some thoughts for this investigation see in TODO.Rmd.
# Ideas for organizing further research see in ideas.Rmd
## Cleaning up the workspace
rm(list=ls(all=TRUE))
## Dependencies
library(ggplot2)  # eye-candy graphs
library(xtable)   # convert data to latex tables
library(outliers) # tests for outliers
library(tseries)  # adf test used
library(nortest)  # tests for normality
library(sp)       # spatial data
library(gstat)    # geostatistics
library(reshape2) # will see
## Import local modules
source("R/lib/plot.R")       # useful functions for more comfortable plotting
source("R/lib/print.R")      # functions for print some data to files
source("R/lib/dstats.R")     # descriptive statistics module
source("R/lib/misc.R")       # some useful global-use functions
source("R/lib/draw.R")       # helpers for drawing
source("R/lib/ntest.R")      # tests for normality
## Read the data / pattern: year;temperature
path.data <- "data/batorino_july.csv" # this for future shiny support and may be choosing multiple data sources
src.nrows <- 38
src.data  <- read.csv(file=path.data, header=TRUE, sep=";", nrows=src.nrows, colClasses=c("numeric", "numeric"), stringsAsFactors=FALSE)
## Global use constants
kDateBreaks <- seq(min(src.data$year) - 5, max(src.data$year) + 5, by=2) # date points for graphs
## For the reason of prediction estimation and comparison, let cut observations number by 3
kObservationNum <- length(src.data[, 1]) - 3
## Source data as basic time series plot: points connected with line
plot.source <- DrawDataRepresentation(data=src.data, filename="source.png", datebreaks=kDateBreaks)
print(xtable(src.data, caption="Исходные данные.", label="table:source"),  table.placement="H",
file="out/original/data.tex")
## Form the data for research
research.data <- src.data[0:kObservationNum, ]
# Getting descriptive statistics for temperature in russian locale
research.data.dstats <- dstats.describe(research.data$temperature, locale=TRUE)
print(xtable(research.data.dstats, caption="Описательные статистики для наблюдаемых температур.", label="table:dstats"),
file="out/original/dstats.tex")
## Basic histogram based on Sturges rule (by default) with pretty output (also by default)
plot.data.hist <- DrawHistogram(data=research.data, filename="original/histogram.png", datebreaks=kDateBreaks)
## Tests for normality
research.data.shapiro <- ntest.ShapiroWilk(data=research.data$temperature, filename="out/original/shapiro-test.tex")
research.data.pearson <- ntest.PearsonChi2(data=research.data$temperature, filename="out/original/pearson-test.tex")
research.data.ks      <- ntest.KolmogorovSmirnov(data=research.data$temperature, filename="out/original/ks-test.tex")
## Normal Quantile-Quantile plot // TODO: check when it appears in text
plot.data.qq <- DrawQuantileQunatile(data=research.data$temperature, filename="original/quantile.png")
## Scatter plot with regression line
plot.data.scatter <- DrawScatterPlot(research.data, filename="original/scatterplot.png", kDateBreaks);
## Grubbs test for outliers
research.data.grubbs <- grubbs.test(research.data$temperature)
to.file(research.data.grubbs, "out/original/grubbs-test.tex")
## Correlation matrix
research.data.cmatrix <- cor(cbind("Temperature"=research.data$temperature, "Date"=1:kObservationNum), method="pearson")
print(xtable(research.data.cmatrix, caption="Корреляционная матрица.", label="table:cmatrix"),
file="out/original/corr-matrix.tex")
## Pearson's product-moment correlation test. Use time for y as numerical
research.data.ctest <- cor.test(research.data$temperature, c(1:kObservationNum), method="pearson")
to.file(research.data.ctest, "out/original/corr-test.tex")
## Fitting linear model for researching data. It also compute residuals based on subtracted regression
research.data.fit <- lm(research.data$temperature ~ c(1:kObservationNum))
## Time series (which is by default is research data) with trend line based on linear module estimate (lm)
plot.data.ts <- DrawTimeSeries(data=research.data, filename="original/time-series.png", datebreaks=kDateBreaks)
## Next step is research residuals computed few lines above
research.residuals <- data.frame("year"=research.data$year, "temperature"=research.data.fit$residuals)
print(xtable(research.residuals, caption="Временной ряд остатков.", label="table:residuals"), table.placement="H",
file="out/residual/data.tex")
## Residuals time series (data have gotten on computing step: fitting linear model)
plot.residuals.ts <- DrawTimeSeries(data=research.residuals, filename="residual/time-series.png", datebreaks=kDateBreaks)
## Descriptive statistics for residuals
research.residuals.dstats <- dstats.describe(research.residuals$temperature, locale=TRUE)
print(xtable(research.residuals.dstats, caption="Описательные статистики для остатков.", label="table:residuals_dstats"),
file="out/residuals_dstats.tex")
## Basic histogram for residuals / seems like the same as for non-residuals
plot.residuals.hist <- DrawHistogram(data=research.residuals, filename="residual/histogram.png", datebreaks=kDateBreaks)
## Tests for normality
research.data.shapiro <- ntest.ShapiroWilk(data=research.residuals$temperature, filename="out/residual/shapiro-test.tex")
research.data.pearson <- ntest.PearsonChi2(data=research.residuals$temperature, filename="out/residual/pearson-test.tex")
research.data.ks      <- ntest.KolmogorovSmirnov(data=research.residuals$temperature, filename="out/residual/ks-test.tex")
## Normal Quantile-Quantile plot for residuals
plot.residuals.qq <- DrawQuantileQunatile(data=research.residuals$temperature, filename="residual/qunatile.png")
## Auto Correlation Function plot // TODO: check the style
plot.residuals.acf <- DrawAutoCorrelationFunction(data=research.data$temperature, filename="residual/acf.png")
## Box-Ljung and adf tests (some kind of stationarity and independence tests) // TODO: need to know exactly in theory what it is
research.residuals.box <- Box.test(research.residuals$temperature, type="Ljung-Box")
to.file(research.residuals.box, "out/residual/ljung-test.tex")
research.residuals.adf <- adf.test(research.residuals$temperature)
to.file(research.residuals.adf, "out/residual/stationarity-test.tex")
source("R/variogram.R")
# Let's start from beginning.
# This file will be the master file of all diploma project's files (slaves).
# Content will be the same as for previous works (batorino analysis).
# Some thoughts for this investigation see in TODO.Rmd.
# Ideas for organizing further research see in ideas.Rmd
## Cleaning up the workspace
rm(list=ls(all=TRUE))
## Dependencies
library(ggplot2)  # eye-candy graphs
library(xtable)   # convert data to latex tables
library(outliers) # tests for outliers
library(tseries)  # adf test used
library(nortest)  # tests for normality
library(sp)       # spatial data
library(gstat)    # geostatistics
library(reshape2) # will see
## Import local modules
source("R/lib/plot.R")       # useful functions for more comfortable plotting
source("R/lib/print.R")      # functions for print some data to files
source("R/lib/dstats.R")     # descriptive statistics module
source("R/lib/misc.R")       # some useful global-use functions
source("R/lib/draw.R")       # helpers for drawing
source("R/lib/ntest.R")      # tests for normality
## Read the data / pattern: year;temperature
path.data <- "data/batorino_july.csv" # this for future shiny support and may be choosing multiple data sources
src.nrows <- 38
src.data  <- read.csv(file=path.data, header=TRUE, sep=";", nrows=src.nrows, colClasses=c("numeric", "numeric"), stringsAsFactors=FALSE)
## Global use constants
kDateBreaks <- seq(min(src.data$year) - 5, max(src.data$year) + 5, by=2) # date points for graphs
## For the reason of prediction estimation and comparison, let cut observations number by 3
kObservationNum <- length(src.data[, 1]) - 3
## Source data as basic time series plot: points connected with line
plot.source <- DrawDataRepresentation(data=src.data, filename="source.png", datebreaks=kDateBreaks)
print(xtable(src.data, caption="Исходные данные.", label="table:source"),  table.placement="H",
file="out/original/data.tex")
## Form the data for research
research.data <- src.data[0:kObservationNum, ]
# Getting descriptive statistics for temperature in russian locale
research.data.dstats <- dstats.describe(research.data$temperature, locale=TRUE)
print(xtable(research.data.dstats, caption="Описательные статистики для наблюдаемых температур.", label="table:dstats"),
file="out/original/dstats.tex")
## Basic histogram based on Sturges rule (by default) with pretty output (also by default)
plot.data.hist <- DrawHistogram(data=research.data, filename="original/histogram.png", datebreaks=kDateBreaks)
## Tests for normality
research.data.shapiro <- ntest.ShapiroWilk(data=research.data$temperature, filename="out/original/shapiro-test.tex")
research.data.pearson <- ntest.PearsonChi2(data=research.data$temperature, filename="out/original/pearson-test.tex")
research.data.ks      <- ntest.KolmogorovSmirnov(data=research.data$temperature, filename="out/original/ks-test.tex")
## Normal Quantile-Quantile plot // TODO: check when it appears in text
plot.data.qq <- DrawQuantileQunatile(data=research.data$temperature, filename="original/quantile.png")
## Scatter plot with regression line
plot.data.scatter <- DrawScatterPlot(research.data, filename="original/scatterplot.png", kDateBreaks);
## Grubbs test for outliers
research.data.grubbs <- grubbs.test(research.data$temperature)
to.file(research.data.grubbs, "out/original/grubbs-test.tex")
## Correlation matrix
research.data.cmatrix <- cor(cbind("Temperature"=research.data$temperature, "Date"=1:kObservationNum), method="pearson")
print(xtable(research.data.cmatrix, caption="Корреляционная матрица.", label="table:cmatrix"),
file="out/original/corr-matrix.tex")
## Pearson's product-moment correlation test. Use time for y as numerical
research.data.ctest <- cor.test(research.data$temperature, c(1:kObservationNum), method="pearson")
to.file(research.data.ctest, "out/original/corr-test.tex")
## Fitting linear model for researching data. It also compute residuals based on subtracted regression
research.data.fit <- lm(research.data$temperature ~ c(1:kObservationNum))
## Time series (which is by default is research data) with trend line based on linear module estimate (lm)
plot.data.ts <- DrawTimeSeries(data=research.data, filename="original/time-series.png", datebreaks=kDateBreaks)
## Next step is research residuals computed few lines above
research.residuals <- data.frame("year"=research.data$year, "temperature"=research.data.fit$residuals)
print(xtable(research.residuals, caption="Временной ряд остатков.", label="table:residuals"), table.placement="H",
file="out/residual/data.tex")
## Residuals time series (data have gotten on computing step: fitting linear model)
plot.residuals.ts <- DrawTimeSeries(data=research.residuals, filename="residual/time-series.png", datebreaks=kDateBreaks)
## Descriptive statistics for residuals
research.residuals.dstats <- dstats.describe(research.residuals$temperature, locale=TRUE)
print(xtable(research.residuals.dstats, caption="Описательные статистики для остатков.", label="table:residuals_dstats"),
file="out/residuals_dstats.tex")
## Basic histogram for residuals / seems like the same as for non-residuals
plot.residuals.hist <- DrawHistogram(data=research.residuals, filename="residual/histogram.png", datebreaks=kDateBreaks)
## Tests for normality
research.data.shapiro <- ntest.ShapiroWilk(data=research.residuals$temperature, filename="out/residual/shapiro-test.tex")
research.data.pearson <- ntest.PearsonChi2(data=research.residuals$temperature, filename="out/residual/pearson-test.tex")
research.data.ks      <- ntest.KolmogorovSmirnov(data=research.residuals$temperature, filename="out/residual/ks-test.tex")
## Normal Quantile-Quantile plot for residuals
plot.residuals.qq <- DrawQuantileQunatile(data=research.residuals$temperature, filename="residual/qunatile.png")
## Auto Correlation Function plot // TODO: check the style
plot.residuals.acf <- DrawAutoCorrelationFunction(data=research.data$temperature, filename="residual/acf.png")
## Box-Ljung and adf tests (some kind of stationarity and independence tests) // TODO: need to know exactly in theory what it is
research.residuals.box <- Box.test(research.residuals$temperature, type="Ljung-Box")
to.file(research.residuals.box, "out/residual/ljung-test.tex")
research.residuals.adf <- adf.test(research.residuals$temperature)
to.file(research.residuals.adf, "out/residual/stationarity-test.tex")
