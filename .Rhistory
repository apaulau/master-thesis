MakeConclusion <- function(statistic, critical, coeff) {
if (abs(statistic) > critical) {
conclusion <- paste("нулевая гипотеза отвергается и отклонение", coeff, "от нуля носит неслучайный характер, и, следовательно, величина", coeff, "значима.", sep=" ")
} else {
conclusion <- paste("для параметра", coeff, "нельзя отвергнуть нулевую гипотезу", sep=" ")
}
conclusion
}
StudentCriticalPoint <- function(alpha, df) {
qt(1 - alpha, df)
}
n <- length(y)
x <- seq(1, n)
fit <- lm(y ~ x)
a <- fit$coefficients[[2]]
b <- fit$coefficients[[1]]
vardev <- var(y) * (1 - cor(y, x)^2)
errorA <- sqrt(vardev) / (sqrt(var(x)) * sqrt(n - 2))
errorB <- sqrt(vardev) / sqrt(n - 2) * sqrt(1 + mean(x)^2 / var(x))
studentA <- a / errorA
studentB <- b / errorB
criticalPoint <- StudentCriticalPoint(alpha, n - 2)
if (write) {
WriteCharacteristic(a, type="original", name="regr-a")
WriteCharacteristic(b, type="original", name="regr-b")
WriteCharacteristic(vardev, type="original", name="regr-vardev")
WriteCharacteristic(errorA, type="original", name="regr-errorA")
WriteCharacteristic(errorB, type="original", name="regr-errorB")
WriteCharacteristic(studentA, type="original", name="regr-studentA")
WriteCharacteristic(studentB, type="original", name="regr-studentB")
WriteCharacteristic(criticalPoint, type="original", name="regr-criticalPoint")
WriteCharacteristic(MakeConclusion(studentA, criticalPoint, paste(math, 'a', math)), type="original", name="regr-conclusionA")
WriteCharacteristic(MakeConclusion(studentB, criticalPoint, paste(math, 'b', math)), type="original", name="regr-conclusionB")
}
list(vardev=vardev, errors=c(errorA, errorB), coeff=c(a, b), statistic=c(studentA, studentB), critical=criticalPoint,
conclusion=c(MakeConclusion(studentA, criticalPoint, paste(math, 'a', math)), MakeConclusion(studentB, criticalPoint, paste(math, 'b', math))))
}
regr.adequacy <- function(y, alpha=.05) {
regression <- function(x, a, b) a * x + b
CriticalPoint <- function(alpha, df1, df2) {
qf(1 - alpha, df1, df2)
}
MakeConclusion <- function(statistic, critical) {
if (statistic > critical) {
conclusion <- "нулевая гипотеза о равенстве дисперсий отвергается, что означает в рассматриваемом случае адекватность регрессионной модели"
} else {
conclusion <- "нельзя отвергнуть нулевую гипотезу о равенстве дисперсий"
}
conclusion
}
n <- length(y)
x <- seq(1, n)
fit <- lm(y ~ x)
a <- fit$coefficients[[2]]
b <- fit$coefficients[[1]]
y_ <- sapply(X=x, FUN=regression, a=a, b=b)
var_ <- 1 / n * sum(sapply(x, FUN=function(j){(y_[j] - mean(y))^2}))
determination <- var_ / var(y)
linearity <- determination - cor(y, x)^2
resvar <- 1 / n * sum(sapply(x, FUN=function(j){(y[j] - y_[j])^2}))
statistic <- (n - 2) * var_ / resvar
critical <- CriticalPoint(alpha, 1, n - 2)
list(modvar=var_, determination=determination, linearity=linearity,
Fisher=list(resvar=resvar, statistic=statistic, critical=critical, conclusion=MakeConclusion(statistic, critical)))
}
sign <- regr.significance(research.data$temperature, math='', write=TRUE)
sign <- regr.significance(research.data$temperature, write=TRUE)
source('~/study/bachelors-thesis/R/lib/regr.R')
sign <- regr.significance(research.data$temperature, write=TRUE)
adeq <- regr.adequacy(research.dat$temperature, write=TRUE)
adeq <- regr.adequacy(research.data$temperature, write=TRUE)
source('~/study/bachelors-thesis/R/lib/regr.R')
adeq <- regr.adequacy(research.data$temperature, write=TRUE)
source('~/study/bachelors-thesis/R/lib/regr.R')
sign <- regr.significance(research.data$temperature, write=TRUE)
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
source('~/study/bachelors-thesis/R/master.R')
source('~/study/bachelors-thesis/R/master.R')
## Cleaning up the workspace
rm(list=ls(all=TRUE))
## Dependencies
library(ggplot2)  # eye-candy graphs
library(xtable)   # convert data to latex tables
library(outliers) # tests for outliers
library(tseries)  # adf test used
library(nortest)  # tests for normality
library(sp)       # spatial data
library(gstat)    # geostatistics
library(reshape2) # will see
## Import local modules
source("R/lib/plot.R")       # useful functions for more comfortable plotting
source("R/lib/dstats.R")     # descriptive statistics module
source("R/lib/misc.R")       # some useful global-use functions
source("R/lib/draw.R")       # helpers for drawing
source("R/lib/write.R")      # helpers for writing
source("R/lib/ntest.R")      # tests for normality
source("R/lib/regr.R")
source("R/lib/measures.R")
## Read the data / pattern: year;temperature
path.data <- "data/batorino_july.csv" # this for future shiny support and may be choosing multiple data sources
src.nrows <- 38
src.data  <- read.csv(file=path.data, header=TRUE, sep=";", nrows=src.nrows, colClasses=c("numeric", "numeric"), stringsAsFactors=FALSE)
## Global use constants
kDateBreaks <- seq(min(src.data$year) - 5, max(src.data$year) + 5, by=2) # date points for graphs
## For the reason of prediction estimation and comparison, let cut observations number by 3
kObservationNum <- length(src.data[, 1]) - 3
WriteCharacteristic(expression=kObservationNum, type="original", name="n")
## Source data as basic time series plot: points connected with line
plot.source <- DrawDataRepresentation(data=src.data, filename="source.png", datebreaks=kDateBreaks)
print(xtable(src.data, caption="Исходные данные.", label="table:source"),  table.placement="H",
file="out/original/data.tex")
## Form the data for research
research.data <- src.data[0:kObservationNum, ]
# Getting descriptive statistics for temperature in russian locale
research.data.dstats <- dstats.describe(research.data$temperature, type="original", locale=TRUE)
print(xtable(research.data.dstats, caption="Описательные статистики для наблюдаемых температур.", label="table:dstats"),
file="out/original/dstats.tex")
# Compute Sturges rule for output
WriteCharacteristic(expression=nclass.Sturges(research.data$temperature), type="original", name="sturges")
## Basic histogram based on Sturges rule (by default) with pretty output (also by default)
plot.data.hist <- DrawHistogram(data=research.data, filename="original/histogram.png")
## Tests for normality
research.data.shapiro <- ntest.ShapiroWilk(data=research.data$temperature, type="original", name="shapiro")
research.data.pearson <- ntest.PearsonChi2(data=research.data$temperature, type="original", name="pearson")
research.data.ks      <- ntest.KolmogorovSmirnov(data=research.data$temperature, type="original", name="ks")
## Normal Quantile-Quantile plot // TODO: check when it appears in text
plot.data.qq <- DrawQuantileQuantile(data=research.data$temperature, filename="original/quantile.png")
## Scatter plot with regression line
plot.data.scatter <- DrawScatterPlot(research.data, filename="original/scatterplot.png", kDateBreaks);
## Grubbs test for outliers
research.data.grubbs <- grubbs.test(research.data$temperature)
WriteTest(research.data.grubbs$statistic, research.data.grubbs$p.value, type="original", name="grubbs")
## Compute correlation for output
research.data.correlation <- cor(x=research.data$year, y=research.data$temperature)
WriteCharacteristic(research.data.correlation, type="original", name="correlation")
## Pearson's product-moment correlation test. Use time for y as numerical
research.data.ctest <- cor.test(research.data$temperature, c(1:kObservationNum), method="pearson")
WriteTest(research.data.ctest$statistic, research.data.ctest$p.value, research.data.ctest$parameter[[1]], type="original", name="correlation")
## Fitting linear model for researching data. It also compute residuals based on subtracted regression
research.data.fit <- lm(research.data$temperature ~ c(1:kObservationNum))
linear <- function(x, a, b) a * x + b
research.residuals.prediction.trend <- data.frame("Год"=src.data$year[(kObservationNum + 1):src.nrows],
"Актуальное"=src.data$temperature[(kObservationNum + 1):src.nrows],
"Прогнозное"=sapply(X=ConvertYearsToNum(src.data$year[(kObservationNum + 1):src.nrows]), FUN=linear, a=research.data.fit$coefficients[[2]], b=research.data.fit$coefficients[[1]]))
print(xtable(research.residuals.prediction.trend, caption="Сравнение прогнозных значений", label="table:prediction_trend", digits=c(0, 0, 2, 2)),
file="out/residual/prediction-trend.tex")
## Time series (which is by default is research data) with trend line based on linear module estimate (lm)
plot.data.ts <- DrawTimeSeries(data=research.data, filename="original/time-series.png", datebreaks=kDateBreaks)
## Next step is research residuals computed few lines above
research.residuals <- data.frame("year"=research.data$year, "temperature"=research.data.fit$residuals)
print(xtable(research.residuals, caption="Временной ряд остатков.", label="table:residuals"), table.placement="H",
file="out/residual/data.tex")
sign <- regr.significance(research.data$temperature, write=TRUE)
adeq <- regr.adequacy(research.data$temperature, write=TRUE)
## Residuals time series (data have gotten on computing step: fitting linear model)
plot.residuals.ts <- DrawTimeSeries(data=research.residuals, filename="residual/time-series.png", datebreaks=kDateBreaks)
## Descriptive statistics for residuals
research.residuals.dstats <- dstats.describe(research.residuals$temperature, type="residual", locale=TRUE)
print(xtable(research.residuals.dstats, caption="Описательные статистики остатков", label="table:residuals_dstats"),
file="out/residual/dstats.tex")
## Basic histogram for residuals / seems like the same as for non-residuals
plot.residuals.hist <- DrawHistogram(data=research.residuals, filename="residual/histogram.png")
## Tests for normality
research.data.shapiro <- ntest.ShapiroWilk(data=research.residuals$temperature, type="residual", name="shapiro")
research.data.pearson <- ntest.PearsonChi2(data=research.residuals$temperature, type="residual", name="pearson")
research.data.ks      <- ntest.KolmogorovSmirnov(data=research.residuals$temperature, type="residual", name="ks")
## Normal Quantile-Quantile plot for residuals
plot.residuals.qq <- DrawQuantileQuantile(data=research.residuals$temperature, filename="residual/quantile.png")
## Auto Correlation Function plot
plot.residuals.acf <- DrawAutoCorrelationFunction(data=research.data$temperature, filename="residual/acf.png")
## Box-Ljung and adf tests (some kind of stationarity and independence tests) // TODO: need to know exactly in theory what it is
research.residuals.box <- Box.test(research.residuals$temperature, type="Ljung-Box")
WriteTest(research.residuals.box$statistic, research.residuals.box$p.value, research.residuals.box$parameter[[1]], type="residual", name="ljung-box")
research.residuals.adf <- adf.test(research.residuals$temperature)
WriteTest(research.residuals.adf$statistic, research.residuals.adf$p.value, type="residual", name="stationarity")
source("R/predictor.R")
source("R/lib/afv.R")
source("R/lib/variogram.R")
source("R/lib/kriging.R")
## Function definition: need to be moved into isolated place
# Completes trend values up to source observation number
computeTrend <- function (fit, future=0) {
c(sapply(c(1 : (src.nrows + future)), FUN=function(x) fit$coefficients[[1]] + x * fit$coefficients[[2]]))
}
# Computes prediction with passed parameters and saves all needed info and plots
processPrediction <- function (data, year, variog=ComputeVariogram, cressie, cutoff, name, caption) {
variogram <- variog(data, x=ConvertYearsToNum(year), cressie=cressie, cutoff=cutoff, name=name, observations=kObservationNum)
WriteCharacteristic(variogram$var_model[[2]][1], type="variogram", name=paste0(name, "-nug"))
WriteCharacteristic(variogram$var_model[[2]][2], type="variogram", name=paste0(name, "-psill"))
WriteCharacteristic(variogram$var_model[[3]][2], type="variogram", name=paste0(name, "-range"))
prediction <- PredictWithKriging(data, x=ConvertYearsToNum(year), observations=kObservationNum, variogram_model=variogram$var_model, nrows=src.nrows)
CrossPrediction(src.data$temperature, src.data$year, research.data.trend, prediction, name, observations=kObservationNum, nrows=src.nrows)
residual <- ComputeKrigingResiduals(src.data$temperature, research.data.trend, prediction, observations=kObservationNum, nrows=src.nrows)
mse <- MSE(residual)
prediction.compare <- data.frame("Год"=src.data$year[(kObservationNum + 1):src.nrows],
"Наблюдение"=src.data$temperature[(kObservationNum + 1):src.nrows],
"Прогноз"=prediction$var1.pred+research.data.trend[(kObservationNum + 1):src.nrows],
"Тренд"=research.data.trend[(kObservationNum + 1):src.nrows])
print(xtable(prediction.compare, caption=caption, label=paste0("table:", name, "-prediction"), digits=c(0, 0, 3, 3, 3)),
file=paste0("out/variogram/", name, "-prediction.tex"))
WriteCharacteristic(mse, type="variogram", name=paste0(name, "-mse"))
list(variogram=variogram, prediction=prediction, residual=residual, mse=mse)
}
kObservationNum <- 32
## Form the data for research again
research.data <- src.data[0:kObservationNum, ]
research.data.fit <- lm(research.data$temperature ~ ConvertYearsToNum(research.data$year))
research.data.residuals <- research.data.fit$residuals
research.data.trend <- computeTrend(research.data.fit)
cutoff <- trunc(2 * kObservationNum / 3) # let it be "classical" value
# Draw H-Scatterplot
research.data.hscat <- DrawHScatterplot(research.data.residuals[1:kObservationNum], cutoff)
# Compute prediction manually with choosed model ("best" what i found)
manual <- processPrediction(data=research.data.residuals, year=research.data$year, variog=ComputeManualVariogram, cressie=FALSE, cutoff=cutoff, name="manual", caption="Прогноз (сферическая модель)")
# Compute prediction with auto fit model using classical estimation
classical <- processPrediction(data=research.data.residuals, year=research.data$year, cressie=FALSE, cutoff=cutoff, name="classical", caption="Прогноз (классическая оценка)")
# Compute prediction with auto fit model using robust (cressie) estimation
robust <- processPrediction(data=research.data.residuals, year=research.data$year, cressie=TRUE, cutoff=cutoff, name="robust", caption="Прогноз (робастная оценка)")
models.comparison <- CompareClassicalModels(manual$variogram, classical$variogram, filename="figures/variogram/models-comparison.png")
# Find best cutoff parameters
cutoff <- ComparePredictionParameters(research.data.residuals, research.data.trend, ConvertYearsToNum(research.data$year), filename="figures/variogram/parameter-comparison.png", observations=kObservationNum, nrows=src.nrows)
manual.best    <- processPrediction(data=research.data.residuals, year=research.data$year, variog=ComputeManualVariogram, cressie=FALSE, cutoff=cutoff$manual, name="manual-best", caption="Наилучший прогноз (сферическая модель)")
classcial.best <- processPrediction(data=research.data.residuals, year=research.data$year, cressie=FALSE, cutoff=cutoff$classical, name="classical-best", caption="Наилучший прогноз (классическая оценка)")
robust.best    <- processPrediction(data=research.data.residuals, year=research.data$year, cressie=TRUE, cutoff=cutoff$robust, name="robust-best", caption="Наилучший прогноз (робастная оценка)")
source('~/study/bachelors-thesis/R/lib/kriging.R')
source('~/study/bachelors-thesis/R/lib/kriging.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/predictor.R')
debugSource('~/study/bachelors-thesis/R/lib/kriging.R')
source("R/lib/afv.R")
source("R/lib/variogram.R")
source("R/lib/kriging.R")
## Function definition: need to be moved into isolated place
# Completes trend values up to source observation number
computeTrend <- function (fit, future=0) {
c(sapply(c(1 : (src.nrows + future)), FUN=function(x) fit$coefficients[[1]] + x * fit$coefficients[[2]]))
}
# Computes prediction with passed parameters and saves all needed info and plots
processPrediction <- function (data, year, variog=ComputeVariogram, cressie, cutoff, name, caption) {
variogram <- variog(data, x=ConvertYearsToNum(year), cressie=cressie, cutoff=cutoff, name=name, observations=kObservationNum)
WriteCharacteristic(variogram$var_model[[2]][1], type="variogram", name=paste0(name, "-nug"))
WriteCharacteristic(variogram$var_model[[2]][2], type="variogram", name=paste0(name, "-psill"))
WriteCharacteristic(variogram$var_model[[3]][2], type="variogram", name=paste0(name, "-range"))
prediction <- PredictWithKriging(data, x=ConvertYearsToNum(year), observations=kObservationNum, variogram_model=variogram$var_model, nrows=src.nrows)
CrossPrediction(src.data$temperature, src.data$year, research.data.trend, prediction, name, observations=kObservationNum, nrows=src.nrows)
residual <- ComputeKrigingResiduals(src.data$temperature, research.data.trend, prediction, observations=kObservationNum, nrows=src.nrows)
mse <- MSE(residual)
prediction.compare <- data.frame("Год"=src.data$year[(kObservationNum + 1):src.nrows],
"Наблюдение"=src.data$temperature[(kObservationNum + 1):src.nrows],
"Прогноз"=prediction$var1.pred+research.data.trend[(kObservationNum + 1):src.nrows],
"Тренд"=research.data.trend[(kObservationNum + 1):src.nrows])
print(xtable(prediction.compare, caption=caption, label=paste0("table:", name, "-prediction"), digits=c(0, 0, 3, 3, 3)),
file=paste0("out/variogram/", name, "-prediction.tex"))
WriteCharacteristic(mse, type="variogram", name=paste0(name, "-mse"))
list(variogram=variogram, prediction=prediction, residual=residual, mse=mse)
}
kObservationNum <- 32
## Form the data for research again
research.data <- src.data[0:kObservationNum, ]
research.data.fit <- lm(research.data$temperature ~ ConvertYearsToNum(research.data$year))
research.data.residuals <- research.data.fit$residuals
research.data.trend <- computeTrend(research.data.fit)
cutoff <- trunc(2 * kObservationNum / 3) # let it be "classical" value
# Draw H-Scatterplot
research.data.hscat <- DrawHScatterplot(research.data.residuals[1:kObservationNum], cutoff)
# Compute prediction manually with choosed model ("best" what i found)
manual <- processPrediction(data=research.data.residuals, year=research.data$year, variog=ComputeManualVariogram, cressie=FALSE, cutoff=cutoff, name="manual", caption="Прогноз (сферическая модель)")
# Compute prediction with auto fit model using classical estimation
classical <- processPrediction(data=research.data.residuals, year=research.data$year, cressie=FALSE, cutoff=cutoff, name="classical", caption="Прогноз (классическая оценка)")
# Compute prediction with auto fit model using robust (cressie) estimation
robust <- processPrediction(data=research.data.residuals, year=research.data$year, cressie=TRUE, cutoff=cutoff, name="robust", caption="Прогноз (робастная оценка)")
models.comparison <- CompareClassicalModels(manual$variogram, classical$variogram, filename="figures/variogram/models-comparison.png")
# Find best cutoff parameters
cutoff <- ComparePredictionParameters(research.data.residuals, research.data.trend, ConvertYearsToNum(research.data$year), filename="figures/variogram/parameter-comparison.png", observations=kObservationNum, nrows=src.nrows)
manual.best    <- processPrediction(data=research.data.residuals, year=research.data$year, variog=ComputeManualVariogram, cressie=FALSE, cutoff=cutoff$manual, name="manual-best", caption="Наилучший прогноз (сферическая модель)")
classcial.best <- processPrediction(data=research.data.residuals, year=research.data$year, cressie=FALSE, cutoff=cutoff$classical, name="classical-best", caption="Наилучший прогноз (классическая оценка)")
robust.best    <- processPrediction(data=research.data.residuals, year=research.data$year, cressie=TRUE, cutoff=cutoff$robust, name="robust-best", caption="Наилучший прогноз (робастная оценка)")
source('~/study/bachelors-thesis/R/predictor.R')
debugSource('~/study/bachelors-thesis/R/lib/kriging.R')
manual <- processPrediction(data=research.data.residuals, year=research.data$year, variog=ComputeManualVariogram, cressie=FALSE, cutoff=cutoff, name="manual", caption="Прогноз (сферическая модель)")
plot.crossprediction
source('~/study/bachelors-thesis/R/lib/draw.R')
source('~/study/bachelors-thesis/R/lib/draw.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/lib/draw.R')
source('~/study/bachelors-thesis/R/predictor.R')
debugSource('~/study/bachelors-thesis/R/lib/kriging.R')
source('~/study/bachelors-thesis/R/lib/kriging.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/lib/draw.R')
source('~/study/bachelors-thesis/R/lib/kriging.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/lib/draw.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/master.R')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
c(1,1,1,1,1)/c(2,2,2,2,2)
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
source('~/study/bachelors-thesis/R/master.R')
format(2, nsmall=2, digits=3)
format(2, nsmall=0, digits=3)
format(2., nsmall=0, digits=3)
format(2.1, nsmall=0, digits=3)
format(2.13, nsmall=0, digits=3)
format(2.136, nsmall=0, digits=3)
source('~/study/bachelors-thesis/R/master.R')
research.data.grubbs
research.data.grubbs$statistic
research.data.grubbs$statistic[G]
research.data.grubbs$statistic[1]
research.data.correlation * sqrt(kObservationNum - 2)/(1 - research.data.correlation^2)
WriteTest(research.data.correlation * sqrt(kObservationNum - 2)/(1 - research.data.correlation^2), 0, kObservationNum - 2, type="original", name="student")
WriteTest(research.data.correlation * sqrt(kObservationNum - 2)/(1 - research.data.correlation^2), 0, kObservationNum - 2, type="original", name="student")
WriteTest(research.data.correlation * sqrt(kObservationNum - 2)/(1 - research.data.correlation^2), 0, qt(1 - 0.05, kObservationNum - 2), type="original", name="student")
research.data.ctest
source('~/study/bachelors-thesis/R/master.R')
source('~/study/bachelors-thesis/R/master.R')
## Cleaning up the workspace
rm(list=ls(all=TRUE))
## Dependencies
library(ggplot2)  # eye-candy graphs
library(xtable)   # convert data to latex tables
library(outliers) # tests for outliers
library(tseries)  # adf test used
library(nortest)  # tests for normality
library(sp)       # spatial data
library(gstat)    # geostatistics
library(reshape2) # will see
## Import local modules
source("R/lib/plot.R")       # useful functions for more comfortable plotting
source("R/lib/dstats.R")     # descriptive statistics module
source("R/lib/misc.R")       # some useful global-use functions
source("R/lib/draw.R")       # helpers for drawing
source("R/lib/write.R")      # helpers for writing
source("R/lib/ntest.R")      # tests for normality
source("R/lib/regr.R")
source("R/lib/measures.R")
## Read the data / pattern: year;temperature
path.data <- "data/batorino_july.csv" # this for future shiny support and may be choosing multiple data sources
nrows <- 38
src  <- read.csv(file=path.data, header=TRUE, sep=";", nrows=nrows, colClasses=c("numeric", "numeric"), stringsAsFactors=FALSE)
## Global use constants
kDateBreaks <- seq(min(src$year) - 5, max(src$year) + 5, by=2) # date points for graphs
## For the reason of prediction estimation and comparison, let cut observations number by 3
kObservationNum <- length(src[, 1]) - 6
WriteCharacteristic(expression=kObservationNum, type="original", name="n")
## Source data as basic time series plot: points connected with line
plot.source <- DrawDataRepresentation(data=src, filename="source.png", datebreaks=kDateBreaks)
print(xtable(src, caption="Исходные данные.", label="table:source"),  table.placement="H",
file="out/original/data.tex")
## Form the data for research
sample <- src[0:kObservationNum, ]
# Getting descriptive statistics for temperature in russian locale
sample.dstats <- dstats.describe(sample$temperature, type="original", locale=TRUE)
print(xtable(sample.dstats, caption="Описательные статистики для наблюдаемых температур.", label="table:dstats"),
file="out/original/dstats.tex")
# Compute Sturges rule for output
WriteCharacteristic(expression=nclass.Sturges(sample$temperature), type="original", name="sturges")
## Basic histogram based on Sturges rule (by default) with pretty output (also by default)
plot.data.hist <- DrawHistogram(data=sample, filename="original/histogram.png")
## Tests for normality
sample.shapiro <- ntest.ShapiroWilk(data=sample$temperature, type="original", name="shapiro")
sample.pearson <- ntest.PearsonChi2(data=sample$temperature, type="original", name="pearson")
sample.ks      <- ntest.KolmogorovSmirnov(data=sample$temperature, type="original", name="ks")
## Normal Quantile-Quantile plot // TODO: check when it appears in text
plot.data.qq <- DrawQuantileQuantile(data=sample$temperature, filename="original/quantile.png")
## Scatter plot with regression line
plot.data.scatter <- DrawScatterPlot(sample, filename="original/scatterplot.png", kDateBreaks);
## Grubbs test for outliers
sample.grubbs <- grubbs.test(sample$temperature)
WriteTest(sample.grubbs$statistic[1], sample.grubbs$p.value, type="original", name="grubbs")
## Compute correlation for output
sample.correlation <- cor(x=sample$year, y=sample$temperature)
WriteCharacteristic(sample.correlation, type="original", name="correlation")
WriteTest(sample.correlation * sqrt(kObservationNum - 2)/(1 - sample.correlation^2), 0, qt(1 - 0.05, kObservationNum - 2), type="original", name="student")
## Pearson's product-moment correlation test. Use time for y as numerical
sample.ctest <- cor.test(sample$temperature, c(1:kObservationNum), method="pearson")
WriteTest(sample.ctest$statistic, sample.ctest$p.value, sample.ctest$parameter[[1]], type="original", name="correlation")
## Fitting linear model for researching data. It also compute residuals based on subtracted regression
sample.fit <- lm(sample$temperature ~ c(1:kObservationNum))
linear <- function(x, a, b) a * x + b
sample.residuals.prediction.trend <- data.frame("Год"=src$year[(kObservationNum + 1):nrows],
"Актуальное"=src$temperature[(kObservationNum + 1):nrows],
"Прогнозное"=sapply(X=ConvertYearsToNum(src$year[(kObservationNum + 1):nrows]), FUN=linear, a=sample.fit$coefficients[[2]], b=sample.fit$coefficients[[1]]))
print(xtable(sample.residuals.prediction.trend, caption="Сравнение прогнозных значений", label="table:prediction_trend", digits=c(0, 0, 2, 2)),
file="out/residual/prediction-trend.tex")
## Time series (which is by default is research data) with trend line based on linear module estimate (lm)
plot.data.ts <- DrawTimeSeries(data=sample, filename="original/time-series.png", datebreaks=kDateBreaks)
## Next step is research residuals computed few lines above
sample.residuals <- data.frame("year"=sample$year, "temperature"=sample.fit$residuals)
print(xtable(sample.residuals, caption="Временной ряд остатков.", label="table:residuals"), table.placement="H",
file="out/residual/data.tex")
sign <- regr.significance(sample$temperature, write=TRUE)
adeq <- regr.adequacy(sample$temperature, write=TRUE)
## Residuals time series (data have gotten on computing step: fitting linear model)
plot.residuals.ts <- DrawTimeSeries(data=sample.residuals, filename="residual/time-series.png", datebreaks=kDateBreaks)
## Descriptive statistics for residuals
sample.residuals.dstats <- dstats.describe(sample.residuals$temperature, type="residual", locale=TRUE)
print(xtable(sample.residuals.dstats, caption="Описательные статистики остатков", label="table:residuals_dstats"),
file="out/residual/dstats.tex")
## Basic histogram for residuals / seems like the same as for non-residuals
plot.residuals.hist <- DrawHistogram(data=sample.residuals, filename="residual/histogram.png")
## Tests for normality
sample.shapiro <- ntest.ShapiroWilk(data=sample.residuals$temperature, type="residual", name="shapiro")
sample.pearson <- ntest.PearsonChi2(data=sample.residuals$temperature, type="residual", name="pearson")
sample.ks      <- ntest.KolmogorovSmirnov(data=sample.residuals$temperature, type="residual", name="ks")
## Normal Quantile-Quantile plot for residuals
plot.residuals.qq <- DrawQuantileQuantile(data=sample.residuals$temperature, filename="residual/quantile.png")
## Auto Correlation Function plot
plot.residuals.acf <- DrawAutoCorrelationFunction(data=sample$temperature, filename="residual/acf.png")
## Box-Ljung and adf tests (some kind of stationarity and independence tests) // TODO: need to know exactly in theory what it is
sample.residuals.box <- Box.test(sample.residuals$temperature, type="Ljung-Box")
WriteTest(sample.residuals.box$statistic, sample.residuals.box$p.value, sample.residuals.box$parameter[[1]], type="residual", name="ljung-box")
sample.residuals.adf <- adf.test(sample.residuals$temperature)
WriteTest(sample.residuals.adf$statistic, sample.residuals.adf$p.value, type="residual", name="stationarity")
source("R/predictor.R")
source("R/lib/afv.R")
source("R/lib/variogram.R")
source("R/lib/kriging.R")
## Function definition: need to be moved into isolated place
# Completes trend values up to source observation number
computeTrend <- function (fit, future=0) {
c(sapply(c(1 : (nrows + future)), FUN=function(x) fit$coefficients[[1]] + x * fit$coefficients[[2]]))
}
# Computes prediction with passed parameters and saves all needed info and plots
processPrediction <- function (data, year, variog=ComputeVariogram, cressie, cutoff, name, caption) {
variogram <- variog(data, x=ConvertYearsToNum(year), cressie=cressie, cutoff=cutoff, name=name, observations=kObservationNum)
WriteCharacteristic(variogram$var_model[[2]][1], type="variogram", name=paste0(name, "-nug"))
WriteCharacteristic(variogram$var_model[[2]][2], type="variogram", name=paste0(name, "-psill"))
WriteCharacteristic(variogram$var_model[[3]][2], type="variogram", name=paste0(name, "-range"))
prediction <- PredictWithKriging(data, x=ConvertYearsToNum(year), observations=kObservationNum, variogram_model=variogram$var_model, nrows=nrows)
CrossPrediction(src.data$temperature, src.data$year, trend, prediction, name, observations=kObservationNum, nrows=nrows)
residual <- ComputeKrigingResiduals(src.data$temperature, trend, prediction, observations=kObservationNum, nrows=nrows)
mse <- MSE(residual)
prediction.compare <- data.frame("Год"=src.data$year[(kObservationNum + 1):nrows],
"Наблюдение"=src.data$temperature[(kObservationNum + 1):nrows],
"Прогноз"=prediction$var1.pred+trend[(kObservationNum + 1):nrows],
"Тренд"=trend[(kObservationNum + 1):nrows])
print(xtable(prediction.compare, caption=caption, label=paste0("table:", name, "-prediction"), digits=c(0, 0, 3, 3, 3)),
file=paste0("out/variogram/", name, "-prediction.tex"))
WriteCharacteristic(mse, type="variogram", name=paste0(name, "-mse"))
list(variogram=variogram, prediction=prediction, residual=residual, mse=mse)
}
trend <- computeTrend(sample.fit)
cutoff <- trunc(2 * kObservationNum / 3) # let it be "classical" value
# Draw H-Scatterplot
sample.hscat <- DrawHScatterplot(sample.residuals[1:kObservationNum], cutoff)
# Compute prediction manually with choosed model ("best" what i found)
manual <- processPrediction(data=sample.residuals, year=sample$year, variog=ComputeManualVariogram, cressie=FALSE, cutoff=cutoff, name="manual", caption="Прогноз (сферическая модель)")
# Compute prediction with auto fit model using classical estimation
classical <- processPrediction(data=sample.residuals, year=sample$year, cressie=FALSE, cutoff=cutoff, name="classical", caption="Прогноз (классическая оценка)")
# Compute prediction with auto fit model using robust (cressie) estimation
robust <- processPrediction(data=sample.residuals, year=sample$year, cressie=TRUE, cutoff=cutoff, name="robust", caption="Прогноз (робастная оценка)")
models.comparison <- CompareClassicalModels(manual$variogram, classical$variogram, filename="figures/variogram/models-comparison.png")
# Find best cutoff parameters
cutoff <- ComparePredictionParameters(sample.residuals, trend, ConvertYearsToNum(sample$year), filename="figures/variogram/parameter-comparison.png", observations=kObservationNum, nrows=nrows)
manual.best    <- processPrediction(data=sample.residuals, year=sample$year, variog=ComputeManualVariogram, cressie=FALSE, cutoff=cutoff$manual, name="manual-best", caption="Наилучший прогноз (сферическая модель)")
classcial.best <- processPrediction(data=sample.residuals, year=sample$year, cressie=FALSE, cutoff=cutoff$classical, name="classical-best", caption="Наилучший прогноз (классическая оценка)")
robust.best    <- processPrediction(data=sample.residuals, year=sample$year, cressie=TRUE, cutoff=cutoff$robust, name="robust-best", caption="Наилучший прогноз (робастная оценка)")
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/predictor.R')
source('~/study/bachelors-thesis/R/predictor.R')
shiny::runApp('R/shiny')
source('~/study/bachelors-thesis/R/master.R')
sample.pearson
qchisq(.95, df=30)
qchisq(.95, df=36)
qchisq(.95, df=29)
source('~/study/bachelors-thesis/R/master.R')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
pritn(out)
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
shiny::runApp('R/shiny')
variogram <- ComputeVariogram(sample.residuals, x=ConvertYearsToNum(src$year), cressie=TRUE, cutoff=6, observations=kObservationNum)
source('~/study/bachelors-thesis/R/master.R')
