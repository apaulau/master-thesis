\newpage
\chapter{Определения и вспомогательные результаты}

Приведём основные теоретические понятия из [\todo{Вставить ссылку}], которыми будем пользоваться в дальнейшем.

Пусть имеется некоторый одномерный признак $X$. Из него извлечена выборка объёма $n$: $x_1, x_2, \ldots, x_n$.

Введём некоторые основные \textit{описательные статистики}.

\section*{Характеристики положения} % (fold)
\label{sec:chars_pos}

\textit{Среднее арифметическое значение} является показателем 
центрального положения, вычисляется по формуле:
\begin{equation*}
	\overline{x} = \frac{1}{n} \sum_{i=1}^n{x_i}.
\end{equation*}

\textit{Квантилем $Q_p$} порядка $p$, $0<p<1$, называется такое значение признака в упорядоченной совокупности, которое делит её в отношении $p: (1 - p)$. К числу наиболее часто применяемых квантилей относятся:
\begin{enumerate}
	\item \textit{медиана} $(p = \frac{1}{2})$;
	\item \textit{квартиль} $(p = \frac{1}{4})$.
\end{enumerate}

Пусть выборка упорядочена по возрастанию: $x_{1}^{*}, \ldots, x_{n}^{*}$. Тогда \textit{медиана} вычисляется по формуле:
\begin{equation*}
Me = \left\{
 \begin{array}{l l}
   x_{l+1}^{*} &, \quad n = 2l + 1, \\
   \\
   \frac{x_l^{*} + x_{l+1}^{*}}{2} &, \quad n = 2l.
 \end{array} \right.
\end{equation*}

% \textit{Модой} $Mo$ называется значение признака в рассматриваемой совокупности, имеющее наибольшую частоту. При определении моды обычно применяют следующие соглашения:
% \begin{itemize}
% 	\item Если все значения вариационного ряда имеют одинаковую частоту, то говорят, что этот ряд не имеет моды; 
% 	\item Если две соседние варианты имеют одинаковую доминирующую частоту, то мода вычисляется как среднее арифметическое этих вариант;
% 	\item Если две не соседние варианты имеют одинаковую доминирующую частоту, то такой вариационного ряда называют бимодальным;
% 	\item Если таких вариант больше двух, то вариационный ряд называют полимодальным.
% \end{itemize}

\section*{Характеристики рассеяния}

Наиболее распространёнными мерами рассеяния являются \textit{размах}, \textit{дисперсия} и \textit{среднеквадратическое отклонение}.

\textit{Размах} определяется по формуле:
\begin{equation*}
	R = x_{max} - x_{min}.
\end{equation*}

\textit{Квартильный размах} --- интервал, содержащий медиану, в который попадает $50\%$ выборки, вычисляется по формуле: 
\begin{equation*}
	R_Q = q_3 - q_1,
\end{equation*}
где $q_3$, $q_1$ --- соответственно, верхний и нижний квартили.

\textit{Выборочной дисперсии} вычисляется по формуле:
\begin{equation*}
	S_x^2 = \frac{\sum{(x_i - \overline{x})^2}}{n}.
\end{equation*}

Также, для вычисления \textit{выборочной дисперсии} используется несмещённая оценка, которая вычисляется по формуле:
\begin{equation*}
	s_x^2 = \frac{\sum{(x_i - \overline{x})^2}}{n - 1}.
\end{equation*}

Оценка \textit{стандартного отклонения} вычисляется по формуле:
\begin{equation*}
	s_x = \sqrt{\frac{\sum{(x_i - \overline{x})^2}}{n - 1}}.
\end{equation*}

Значение стандартного отклонения можно представить, как среднее расстояние, на котором находятся элементы от среднего элемента выборки, и оно показывает, насколько хорошо среднее значение описывает всю выборку.

В качестве меры относительного разброса данных используют \textit{коэффициент вариации}:
\begin{equation*}
	V = \frac{s_x}{\overline{x}} \cdot 100\%.
\end{equation*}

Данная мера показывает, какую долю среднего значения этой величины составляет её средний разброс. На основе значения коэффициента вариации, можно сделать вывод об однородности выборки: 
\begin{itemize}
	\item Если $V < 33\%$ --- принято считать, что выборка однородна;
	\item Если $V > 33\%$ --- не однородна.
\end{itemize}

\textit{Стандартная ошибка} среднего значения вычисляется как:
\begin{equation*}
	s_{\overline{x}} = \frac{s_x}{\sqrt{n}}.
\end{equation*}

Данная величина оценивает выборочную изменчивость среднего значения, приближённо показывая, насколько выборочное среднее отличается отсреднего генеральной совокупности.

% section chars_pos (end)

\section*{Характеристики формы распределения} % (fold)
\label{sec:chars_distr}

Характеристики формы распределения применяются для выражения особенностей формы распределения.

\textit{Выборочный коэффициент асимметрии} определяется следующим образом:
\begin{equation}
\label{eq:skew}
	A_S = \frac{n\sum{(x_i - \overline{x})^3}}{(n - 1)(n - 2)s_x^3}.
\end{equation}

Данный коэффициент характеризует степень смещения вариационного ряда относительно среднего значения по величине и направлению. В симметричном распределении коэффициент асимметрии равен нулю. 
\begin{itemize}
	\item Если $\vert A_S \vert > 1$, то распределение является в значительной степени асимметричным. 
	\item Если $\frac{1}{2} < \vert A_S \vert \le 1$, то распределение незначительно асимметрично. 
	\item Если $\vert A_S \vert \le \frac{1}{2}$, то распределение является близким к симметричному\todo{Ссылка на литературу}.
\end{itemize}

\textit{Стандартная ошибка выборочного коэффициента асимметрии} \eqref{eq:skew} вычисляется по формуле:
\begin{equation*}
	SES= \sqrt{\frac{6n(n - 1)}{(n - 2)(n + 1)(n + 3)}},
\end{equation*}
где $n$ --- объём выборки.

Для того, чтобы сделать в дальнейшем какие-либо выводы по значению коэффициента асимметрии введём \textit{тестовую статистику}: 
\begin{equation*}
	Z_{A_S}=\frac{A_S}{SES}.
\end{equation*}

\begin{itemize}
	\item Если $\vert Z_{A_S} \vert \ge 2$, то асимметрия существенная и распределение признака в генеральной совокупности несимметрично;
	\item Если $\vert Z_{A_S} \vert < 2$, то асимметрия несущественна.
\end{itemize}
Данная тестовая статистика показывает: насколько существенным является коэффициент асимметрии данной выборки по отношению к генеральной совокупности\todo{Ссылка на литературу}. 

\textit{Выборочный коэффициент эксцесса} вычисляется по формуле:
\begin{equation*}
	K = \frac{n(n + 1) \sum{(x_i - \overline{x})^4} - 3(\sum{(x_i - \overline{x})^2})^2 (n - 1)}{(n - 1)(n - 2)(n - 3)s_x^4}.
\end{equation*}

В случае нормального распределения \textit{коэффициент эксцесса} равен нулю. Положительный \textit{коэффициент эксцесса} характеризует крутость(островершинность) кривой распределения относительно нормального распределения. Отрицательный, в свою очередь, пологость.

\textit{Стандартная ошибка коэффициента эксцесса} может быть вычислена по формуле:
\begin{equation*}
	SEK = 2(SES) \sqrt{\frac{(n^2 - 1)}{(n - 3)(n + 5)}},
\end{equation*}
где $n$ --- объём выборки.

По аналогии с коэффициентом асимметрии, введём также \textit{тестовую статистику} $Z_K$ для коэффициента эксцесса.
\begin{equation*}
	Z_K = \frac{K}{SEK}.
\end{equation*}

\begin{itemize}
	\item Если $\vert Z_K \vert > 2$, то коэффициент эксцесса является значимым;
	\item Если $\vert Z_K \vert \le 2$, то коэффициент эксцесса не является значимым и нельзя сделать никаких заключений о коэффициенте эксцесса генеральной совокупности\todo{Ссылка на литературу}.
\end{itemize}

% section chars_distr (end)

\section*{Выборочный коэфициент корреляции} % (fold)
\label{sec:correlation}

Для оценки тесноты линейной связи между признаками используется парный линейный \textit{коэффициент корреляции Пирсона}, который определяется формулой:
\begin{equation}
\label{eq:correlation}
	r_{xt} = \frac{S_{xt}}{S_x S_t},
\end{equation}
где $S_{xt} = \frac{1}{n} \sum{(x_i - \overline{x})(t_i - \overline{t})}$, $S_x = \sqrt{\frac{1}{n} \sum{(x_i-\overline{x})^2}}$, $S_t = \sqrt{\frac{1}{n} \sum{(t_i - \overline{t})^2}}$.

Коэффициент корреляции характеризует силу связи и направление. Если $-1 \le r_{xt} < 0$, то наблюдается отрицательная корреляция, если $0 < r_{xt} \le 1$, то наблюдается положительная корреляция.

Для описания силы связи \textit{коэффициента корреляции} используются градации, обозначенные в таблице \ref{table:corr}, где в качестве значения коэффициента корреляции указано абсолютное значение $\vert r_{xt} \vert$.
\begin{center}
\begin{table}[ht]
\label{table:corr}
	\caption{Абсолютные значения коэффициента корреляции}
	\centering
	%\rowcolors{1}{grey}
	\begin{tabular}{c|l}
		\textbf{Абсолютное значение} & \textbf{Интерпретация} \\
		$0$---$0.2$ & Очень слабая зависимость \\
		$0.2$---$0.5$ & Слабая зависимость \\
		$0.5$---$0.7$ & Средняя зависимость \\
		$0.7$---$0.9$ & Высокая зависимость \\
		$0.9$---$1$ & Очень высокая зависимость \\
	\end{tabular}
\end{table}
\end{center}

\section*{Критерий значимости выборочного коэффициента корреляции} % (fold)
\label{subsec:sign_corr}

Пусть двумерная генеральная совокупность $(X, t)$ распределена нормально. Из этой совокупность извлечена выборка объёма $n$ и по ней найден выборочный коэффициент корреляции $r_{xt} \ne 0$.

Требуется проверить нулевую гипотезу $H_0: r = 0$, при конкурирующей гипотезе $H_1: r \ne 0$.

Для того чтобы при заданном уровне значимости $\alpha$ проверить нулевую гипотезу $H_0$, надо вычислить наблюдаемое значение критерия
\begin{equation*}
	T_{\textrm{набл}} = \frac{r_{xt}\sqrt{n - 2}}{\sqrt{1 - r_{xt}^{2}}},
\end{equation*}
где $r_{xt}$ --- выборочный коэффициент корреляции, и по таблице критических точек распределения Стьюдента, по заданному уровню значимости $\alpha$ и числу степеней свободы $k = n - 2$, где $n$ --- число пар значений выборки, найти критическую точку $t_{\textrm{кр}}(\alpha, k)$ для двусторонней критической области.
\begin{itemize}
	\item Если $\vert T_{\textrm{набл}} \vert < t_{\textrm{кр}(\alpha, k)}$ --- нет оснований отвергнуть нулевую гипотезу.
	\item Если $\vert T_{\textrm{набл}} \vert > t_{\textrm{кр}(\alpha, k)}$ --- нулевую гипотезу отвергают.
\end{itemize}

Величина $T_{\textrm{набл}}$ при справедливости нулевой гипотезы имеет распределение Стьюдента с $k = n - 2$ степенями свободы, если нулевая гипотеза отвергается, то это означает, что выборочный коэффициент корреляции значимо отличается от нуля, а исследуемые переменные коррелированы.

% subsection sign_corr (end)
% section correlation (end)

Приведём некоторые критерии, которые понадобятся в нашем исследовании. Для этого воспользуемся литературой\todo{Ссылки на литературу}.

\section*{Критерий Шапиро--Уилка} % (fold)
\label{sec:shapiro_wilk}

Критерий Шапиро--Уилка используется для проверки гипотезы $H_0$: <<генеральная совокупность распределена нормально>> и является одним наиболее эффективных критериев проверки нормальности. \todo[size=\tiny]{+cite: Shapiro S.S., Francia R.S. An appriximate analysis of variance test fo nor­mality // J. Amer. Statist. Assoc., 337, 1972. – P.215-216.}

Пусть имеется вариационный ряд $x_{(1)} \le x_{(2)} \le \ldots \le x_{(n)}$, построенный по извлечённой из генеральной совокупности выборки $x_1, x_2, \ldots, x_n$.

Для того, чтобы при заданном уровне значимости $\alpha$ проверить нулевую гипотезу $H_0$ необходимо вычислить статистику:
\begin{equation*}
	W = \frac{(\sum_{i=1}^{k}{a_{(n-i+1)} (x_{(n-i+1)} - x_{(i)})})^2}{\sum_{i=1}^{n}{(x_i - \overline{x})^2}},
\end{equation*}
где коэффициенты $a_{(n-i+1)}$ --- известные константы, представленные в таблицах из [\todo[size=\tiny]{Shapiro S. S., Wilk M. B. An analysis of variance test for normality. — Biometrika, 1965, 52, №3 — p. 591-611.}], индекс $k$ вычисляется следующим образом:
\begin{equation*}
k = \left\{
 \begin{array}{l l}
   (n-1) / 2 &, \quad n = 2l + 1, \\
   n / 2 &, \quad n = 2l.
 \end{array} \right.
\end{equation*} 
И по заданному уровню значимости $\alpha$ из таблицы критических значений статистики $W(\alpha)$ [\todo[size=\tiny]{Shapiro S. S., Wilk M. B. An analysis of variance test for normality. — Biometrika, 1965, 52, №3 — p. 591-611.}] найти критическую точку $W_{\textrm{кр}}(\alpha)$.
\begin{itemize}
	\item Если $W < W_{\textrm{кр}}(\alpha)$ --- нулевую гипотезу отклоняют.
	\item Если $W > W_{\textrm{кр}}(\alpha)$ --- нет оснований отклонять нулевую гипотезу.\end{itemize}\todo[size=\tiny]{+cite: Кобзарь А. И. Прикладная математическая статистика. — М.: Физматлит, 2006. — 238 с}
% section shapiro_wilk (end)

\section*{Критерий $\chi^2$} % (fold)
\label{sec:chisq}
Пусть нулевая гипотеза $H_0$ состоит в том, что генеральная совокупность распределена нормально.

Для того, чтобы при заданном уровне значимости $\alpha$ проверить нулевую гипотезу $H_0$: генеральная совокупность распределена нормально, необходимо вычислить наблюдаемое значение критерия
\begin{equation*}
	\chi_{\textrm{набл}}^2 = \sum{\frac{(n_i-n'_i)^2}{n'_i}},
\end{equation*}
и по таблице критических точек распределения $\chi^2$, по заданному уровню значимости $\alpha$ и числу степеней свободы $k = s-3$ найти критическую точку $\chi_{\textrm{кр}}^2(\alpha, k)$, где $n_i$ --- эмпирические частоты, а $n'_i$ --- теоретические, $s$ --- число групп (частичных интервалов) выборки[\todo{Ссылку на источник}].
\begin{itemize}
	\item Если $\chi_{\textrm{набл}}^2 < \chi_{\textrm{кр}}^2(\alpha, k)$ --- нет оснований отвергать нулевую гипотезу.
	\item Если $\chi_{\textrm{набл}}^2 > \chi_{\textrm{кр}}^2(\alpha, k)$ --- нулевую гипотезу отвергают.
\end{itemize}

% section chisq (end)

\section*{Критерий Колмогорова---Смирнова} % (fold)
\label{sec:kolm_smirn}

Пусть нулевая гипотеза $H_0$ состоит в том, что генеральная совокупность распределена нормально.

Критерий заключается в том, что можно сравнивать эмпирическую функцию распределения $F^{*}(x)$ с гипотетической $F(x)$ и, если мера расхождения между ними мала, то считать справедливой гипотезу $H_0$.

Для того, чтобы при заданном уровне значимости проверить нулевую гипотезу $H_0$: генеральная совокупность распределена нормально, необходимо вычислить статистику Колмогорова-Смирнова 
\begin{equation*}
	D = \sqrt{n}\max_{x} \vert F^{*}(x) - F(x) \vert 
\end{equation*}
и по таблице критических значений статистики Колмогорова--Смирнова, по заданному уровню значимости $\alpha$ найти критическую точку $D_{\textrm{кр}}(\alpha)$.
\begin{itemize}
	\item Если $D < D_{\textrm{кр}}(\alpha)$ --- нет оснований отвергать нулевую гипотезу.
	\item Если $D > D_{\textrm{кр}}(\alpha)$ --- нулевую гипотезу отвергают.
\end{itemize}

% section kolm_smirn (end)

\section*{Критерий Граббса} % (fold)
\label{sec:grabbs}

\todo{Ссылка}Критерий Граббса основан на предположении о нормальности исходных данных. То есть, перед применением данного критерия необходимо убедиться, что данные могут быть в разумных пределах аппроксимированы нормальным распределением.

Критерий Граббса обнаруживает один выброс за одну процедуру проверки. Найденный выброс исключается из выборки и процедура проверки критерия проверяется пока не будут исключены все выбросы. Не рекомендуется использовать данный критерий для выборок объёмом ниже 7.

Данный критерий заключается в проверке нулевой гипотезы $H_0:$ в выборке нет выбросов, при конкурирующей гипотезе $H_1:$ в выборке есть по крайней мере $1$ выброс.

Статистика критерия Граббса определяется следующим образом:
\begin{equation*}
	G = \frac{\max \vert y_i - \overline{y} \vert}{s_y},
\end{equation*}
где $\overline{y}$ --- выборочное среднее, $s_y$ - выборочное стандартное отклонение.

Гипотеза $H_0$ отклоняется (значение $y_i$ является выбросом) при заданном уровне значимости $\alpha$, если
\begin{equation*}
	G > \frac{n-1}{\sqrt{n}} \sqrt{\frac{t_{\left( \frac{\alpha}{2n}, n - 2 \right)}^2}{n - 2 + t_{\left( \frac{\alpha}{2n}, n - 2 \right)}^2}},
\end{equation*}
где $n$ --- объём выборки, $t_{\left( \frac{\alpha }{2n}, n - 2 \right)}$ является критическим значением t-распределения с $n - 2$ степенями свободы и уровнем значимости $\frac{\alpha}{2n}$.

% section grabbs (end)

\section*{Характеристики линейной регрессии} % (fold)
\label{sec:chars_regr}

Для введения следующих понятий воспользуемся\todo{Ссылки на литературу}.

Предположим, что уравнение регрессии имеет вид: $x^{*}(t) = at + b$. Тогда \textit{объяснённая уравнением регрессии дисперсия}, характеризующая изменчивость линии регрессии относительно среднего значения, вычисляется по формуле:
\begin{equation}
\label{eq:var_regr}
	\overline{\sigma^2} = \frac{1}{n} \sum_{j=1}^{n}{(x^{*}(t_j) - \overline{x})^2},
\end{equation}
где $x$ --- выборка, $\overline{x}$ --- выборочное среднее.

\textit{Остаточная дисперсия} $\overline{D}$, характеризующая отклонение уравнения регрессии от результатов наблюдений $x$ вычисляется по формуле:
\begin{equation}
\label{eq:var_res}
	\overline{D} = \frac{1}{n} \sum_{j=1}^{n}{(x_j - x^{*}(t_j))^2}.
\end{equation}

Тогда, \textit{общая дисперсия} введённой ранее выборки $x$ будет равна сумме \ref{eq:var_regr} и \ref{eq:var_res}:
\begin{equation*}
	S_x^2 = \overline{D} + \overline{\sigma^2}.
\end{equation*}

\textit{Дисперсия отклонения} вычисляется по формуле:
\begin{equation*}
	\sigma_{\varepsilon}^2 = s_x^2(1 - r_{xt}^2),
\end{equation*}
где $r_{xt}$ --- выборочный коэффициент корреляции.

\textit{Стандартные случайные погрешности} параметров $a$ и $b$:
\begin{equation*}
	\sigma_a = \frac{\sigma_{\varepsilon }}{S_x \sqrt{n - 2}}, \quad \sigma_b = \frac{\sigma_{\varepsilon}}{\sqrt{n-2}} \sqrt{1 + \frac{\overline{x}^2}{S_x^2}},
\end{equation*}
где $S_x$, $S_x^2$ --- стандартное отклонение и дисперсия соответственно.

\textit{Коэффициент детерминации} показывает долю дисперсии исходного ряда, которая описывается моделью регрессии, вычисляется по формуле:
\begin{equation*}
	\eta_{x(t)}^2 = \frac{\overline{\sigma^2}}{s_x^2}.
\end{equation*}

Применяя неравенство $\eta_{y(x)}^2 - r_{xy}^2 \le 0.1$, можно сделать вывод об отклонении от линейности.

\subsection*{Критерий значимости коэффициентов регрессии} % (fold)
\label{subsec:sign_regr}

Пусть нулевая гипотеза заключается в равенстве нулю коэффициентов линейной регрессии $H_0: a=0, b=0$.

Для проверки нулевой гипотезы $H_0: a=0, b=0$ необходимо рассчитать:
\begin{equation*}
	T_a = \frac{a}{\sigma_a}, \quad T_b = \frac{b}{\sigma_b},
\end{equation*}
по статистической таблице определить $t_{\textrm{кр}} \left( k, \alpha \right)$ --- критическую точку t-распределения Стьюдента при заданном уровне значимости $\alpha$ и числе степеней свободы $k = n - 2$.
\begin{itemize}
	\item Если $\left| T_a \right| > t_{\textrm{кр}} \left( k, \alpha \right)$, то нулевая гипотеза	отвергается и отклонение $a$ от нуля носит неслучайный характер, и, следовательно, величина $a$ значима;
	\item Если $\vert T_b \vert > t_{\textrm{кр}} \left( k, \alpha \right)$, то нулевая гипотеза отвергается, отклонение $b$ от нуля носит неслучайный характер, и, следовательно, величина $b$ значима.
\end{itemize}

% subsection sign_regr (end)

\subsection*{Критерий Фишера} % (fold)
\label{subsec:fisher}

Данный критерий используется для оценки адекватности регрессионной модели.

Пусть выдвинута нулевая гипотеза о равенстве дисперсий 
\begin{equation*}
	H_0: \overline{\sigma^2} = \frac{\overline{D}}{n - 2}.
\end{equation*}
Для проверки данной гипотезы используется F-критерий Фишера. Необходимо вычислить дисперсионное отношение 
\begin{equation*}
	F_{\textrm{крит}} = \frac{(n-2)\overline{\sigma^2}}{\overline{D}},	
\end{equation*}
которое сравнивается с $F_{\textrm{табл}}(v_1, v_2, \alpha)$ при заданном уровне значимости $\alpha$, и степенях свободы $v_1=1, v_2=n - 2$. 

Если $F_{\textrm{крит}} > F_{\textrm{табл}}$, то нулевая гипотеза о равенстве дисперсий отвергается, что означает в рассматриваемом случае адекватность регрессионной модели.

% subsection fisher (end)

% section chars_regr (end)